{
 "metadata": {
  "name": "",
  "signature": "sha256:2bb264e7380375e69ef3d90b6ceac3260a51f0837c30f28ddd1fe22d472b6793"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_nltk_dir = \"/home/researcher/nltk_data\"\n",
      "if user_nltk_dir not in nltk.data.path:\n",
      "    nltk.data.path.insert(0, user_nltk_dir)\n",
      "nltk.download(\"book\", download_dir=user_nltk_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.book import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(text2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(text2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(text2)/len(set(text2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vocab(text):\n",
      "    return len(text)/len(set(text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab(text2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(word.lower() for word in text2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(word.lower() for word in text2 if word.isalpha()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text2.concordance('monstrous')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print text2.similar('monstrous')\n",
      "print \"-----\"\n",
      "print text1.similar('monstrous')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text2.common_contexts([\"monstrous\", \"very\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text2.count('he')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text2.count('him')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text2.count('she')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text2.count('her')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist1=FreqDist(text1)\n",
      "print(fdist1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fdist1.most_common(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist1['whale']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist1.plot(50, cumulative=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text4.count(\"American\")+text4.count(\"citizen\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "100.0*text4.count(\"America\")/len(text4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "V= set(text4)\n",
      "long_words = [word for word in V if len(word) > 15]\n",
      "sorted(long_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist5 = FreqDist(text5)\n",
      "sorted (w for w in set(text5) if len(w)>7 and fdist5[w]>7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text4.collocations()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist= FreqDist(len(w) for w in text1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist.most_common()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import word_tokenize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = nltk.word_tokenize(\"And now for something completely different\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.pos_tag(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text2 = nltk.word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
      "nltk.pos_tag(text2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown\n",
      "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
      "tag_fd.most_common()[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tag_fd.plot(cumulative=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make a list of bigrams\n",
      "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
      "#pull out all the words that precede nouns\n",
      "noun_preceders = [a[1] for (a,b) in word_tag_pairs if b[1] == 'NOUN']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist = nltk.FreqDist(noun_preceders)\n",
      "[tag for (tag, _) in fdist.most_common()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news = nltk.corpus.treebank.tagged_words(tagset='universal')\n",
      "word_tag_fd = nltk.FreqDist(news)\n",
      "[wt[0] for (wt, _) in word_tag_fd.most_common() if wt[1] == 'VERB'][:25]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd1 = nltk.ConditionalFreqDist(news)\n",
      "cfd1['yield'].most_common()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news = nltk.corpus.treebank.tagged_words()\n",
      "cfd2 = nltk.ConditionalFreqDist((tag,word) for (word,tag) in news)\n",
      "list(cfd2['VBN'])[:25]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "brown_learned_tagged = brown.tagged_words(categories='learned', tagset='universal')\n",
      "tags = [b[1] for (a, b) in nltk.bigrams(brown_learned_tagged) if a[0] == 'often']\n",
      "fd = nltk.FreqDist(tags)\n",
      "fd.tabulate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib import urlopen"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#open a raw text file from online - in this case, from Project Gutenberg - and read it in\n",
      "url = \"http://www.gutenberg.org/files/863/863.txt\"\n",
      "raw = urlopen(url).read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tokenize into words\n",
      "tokens = nltk.word_tokenize(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#break into sentences\n",
      "sentence = nltk.sent_tokenize(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#average length of sentence\n",
      "len(tokens)/len(sentence)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!unzip UMA_Fraser_Radio_Talks.zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#access items in the directory 'UMA_Fraser_Radio_Talks' and view the first 3\n",
      "os.listdir('UMA_Fraser_Radio_Talks')[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#view the first 100 charaters of the first file\n",
      "open('UMA_Fraser_Radio_Talks/' + os.listdir('UMA_Fraser_Radio_Talks')[0]).read()[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#open the first file, read it into Python and split it into two items, metadata and body \n",
      "data = open('UMA_Fraser_Radio_Talks/' + os.listdir('UMA_Fraser_Radio_Talks')[0]).read().split(\"<!--end metadata-->\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#view the first part\n",
      "data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#split the metadata component into lines on '\\r\\n', add a * to the start of each line\n",
      "for line in data[0].split('\\r\\n'):\n",
      "    print '*', line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get rid of empty lines and any line that starts with '<'\n",
      "for line in data[0].split('\\r\\n'):\n",
      "    if not line: \n",
      "        continue\n",
      "    if line[0] == '<':\n",
      "        continue\n",
      "    print '*', line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#split the metadata items on ':' so that we can interrogate each one\n",
      "for line in data[0].split('\\r\\n'):\n",
      "    if not line: \n",
      "        continue\n",
      "    if line[0] == '<':\n",
      "        continue\n",
      "    element = line.split(':') \n",
      "    print '*', element"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#actually, only split on the first colon\n",
      "for line in data[0].split('\\r\\n'):\n",
      "    if not line: \n",
      "        continue\n",
      "    if line[0] == '<':\n",
      "        continue\n",
      "    element = line.split(':', 1) \n",
      "    print '*', element"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = {}\n",
      "pos['colourless'] = 'ADJ'\n",
      "pos['ideas'] = 'N'\n",
      "pos['sleep'] = 'V'\n",
      "pos['furiously'] = 'ADV'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos['ideas']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make a dictionary of items in the metadata section\n",
      "metadata = {}\n",
      "for line in data[0].split('\\r\\n'):\n",
      "    if not line: \n",
      "        continue\n",
      "    if line[0] == '<':\n",
      "        continue\n",
      "    element = line.split(':', 1) \n",
      "    metadata[element[0]] = element[-1]\n",
      "print metadata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#look up the date\n",
      "print metadata['Date']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make a function so that we can break up the metadata for each file, and get rid of the whitespace at the start of each element \n",
      "def parse_metadata(text):\n",
      "    metadata = {}\n",
      "    for line in text.split('\\r\\n'):\n",
      "        if not line: \n",
      "            continue\n",
      "        if line[0] == '<':\n",
      "            continue\n",
      "        element = line.split(':', 1) \n",
      "        metadata[element[0]] = element[-1].strip(' ')\n",
      "    return metadata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import conditional frequency distribution\n",
      "from nltk.probability import ConditionalFreqDist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfdist = ConditionalFreqDist()\n",
      "for filename in os.listdir('UMA_Fraser_Radio_Talks'):\n",
      "    text = open('UMA_Fraser_Radio_Talks/' + filename).read()\n",
      "    #split text of file on 'end metadata'\n",
      "    text = text.split(\"<!--end metadata-->\")\n",
      "    #parse metadata using previously defined function \"parse_metadata\"\n",
      "    metadata = parse_metadata(text[0])\n",
      "    #skip all speeches for which there is no exact date\n",
      "    if metadata['Date'][0] == 'c':\n",
      "        continue\n",
      "    #build a frequency distribution graph by year, that is, take the final bit of the 'Date' string after '/'\n",
      "    cfdist['count'][metadata['Date'].split('/')[-1]] += 1\n",
      "cfdist.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfdist2 = ConditionalFreqDist()\n",
      "for filename in os.listdir('UMA_Fraser_Radio_Talks'):\n",
      "    text = open('UMA_Fraser_Radio_Talks/' + filename).read()\n",
      "    #split text of file on 'end metadata'\n",
      "    text = text.split(\"<!--end metadata-->\")\n",
      "    #parse metadata using previously defined function \"parse_metadata\"\n",
      "    metadata = parse_metadata(text[0])\n",
      "    #skip all speeches for which there is no exact date\n",
      "    if metadata['Date'][0] == 'c':\n",
      "        continue\n",
      "    #build a frequency distribution graph by 'Description'\n",
      "    cfdist2['count'][metadata['Description']] += 1\n",
      "cfdist2.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tokenize the body of the text so that we can start to analyse it\n",
      "tokens = word_tokenize(data[1])\n",
      "tokens.count('should')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}