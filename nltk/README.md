# ResBaz 2015:
## Data Carpentry with NLTK and IPython

<br>
<img style="float:left" src="http://ipython.org/_static/IPy_header.png" />
<br><br><br>

This is a short line of the ResBaz NLTK sessions. It provides an overview of the main things being taught in the stream, as well as some links to additional resources.

# Session 1: Orientation

In this session, you will learn how to use IPython Notebooks, as well as how to complete basic tasks with Python/NLTK. 

* What exactly are *Python*, *IPython* and *NLTK*?
* Introductions to *IPython Notebook*
* Overview of basic Python concepts: *significant whitespace*, *input/output types*, *commands and arguments*, *functions*, *importing libraries*
* Introduction to NLTK
* Quickstart: *US Inaugural Addresses Corpus*
* **Activity**: plot key terms in the inaugural addresses longitudinally
* What kinds of things can we use this approach for? 
* What are its limitations?
* Basic counting of lexical and metadata items in NLTK builtin corpora

# Session 2: Common NLTK tasks

In this session we provide an overview of research areas using NLTK, such as *Corpus linguistics*, *Natural language processing*, *Distance reading*. We then engage with common uses of NLTK within these areas, such as sentence segmentation, tokenisation and stemming. Often, NLTK has inbuilt methods for performing these tasks. As a learning exercise, however, we will sometimes build basic tools from scratch.

* Overview of common tasks, and why we need them
* Sentence splitting: trivial or not?
* Tokenisation: defining a word and operationalising this definition
* Word and keyword lists
* Stemming: finding a word's *stem form*.
* **Activity:** stemming via [Regular Expressions](http://www.regular-expressions.info/) and then by NLTK stemmer

# Session 3: The Fraser Speech Corpus

We've now got a pretty solid understanding of NLTK. There's still a lot more to learn about NLTK and Python, though! In Session 3, we introduce the Fraser Speeches Corpus, and interrogate this dataset using more complex NLTK functions.

* Building and storing more complex functions
* Splitting texts
*Introduction to Fraser Corpus
* Working with metadata to build subcorpora
* **Activity:** doing Session 1/2 stuff on the Fraser Corpus

# Session 4: Advanced NLTK usage

By this point, we're familiar with NLTK and the Fraser Speeches Corpus. To learn more about language use in this corpus, we first have to parse it for word classes and grammatical structure. We can then interrogate this value-added data in more nuanced ways.

* POS tagging
* Parsing
* Complex queries: overview and uses
* IPython and Shell scripting
* **Activity:** Creating a profile of the Fraser Corpus

# Session 5: Charting change in Fraser's speeches

In this session, we will break into groups to investigate subcorpora of Fraser's speeches. At the end of the lesson, we will synthesise our results to understand how his use of language has changed throughout his career.

* The importance of data structuring
* Splitting up the Fraser Corpus into n parts
* **Team activity:** profiling the langauge of a subcorpus 
* **Group activity:** piecing our subcorpora back together and forming a picture of longitudinal change in Fraser's speeches

# Session 6: Getting the most out of what we've learned

So, we've learned some great skills! But, we need to know how to put these skills into practice within our own work. Using the Fraser Speech Corpus data and our findings, we'll conclude the stream by focussing on:

* Storing your data and results
* Using what youâ€™ve found
* Summary
* Accessing your work here?

# Additional resources

Here are some links that may come in handy if you want more information about what the NLTK stream is all about.

* [IPython homepage](http://ipython.org/): local machine installation, documentation, add-ons
* [NLTK homepage](http://www.nltk.org/): much of what is covered in this stream is also available in the NLTK Book, which is available both online and in print
* [Figshare](http://figshare.com/): for uploading your raw findings
* [Github](https://github.com): a home for you code, with version control
* [ResBaz materials on Github](https://github.com/resbaz): where all the open-source ResBaz materials can be found, including the IPython Notebooks and functions for turning them into .py, .tex, .html or .md files
* [Stack Overflow](http://stackoverflow.com/): many common Python/IPython/NLTK/Regex/Shell questions and answers can be found here.
